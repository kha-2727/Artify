{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09013c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "import dlib"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9980e27a",
   "metadata": {},
   "source": [
    "# Applying Lipstick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be6a7b5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detector=dlib.get_frontal_face_detector()\n",
    "predictor=dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "def createBox(img,points):\n",
    "\n",
    "    mask=np.zeros_like(img)\n",
    "    mask=cv2.fillPoly(mask,[points],(255,255,255))\n",
    "    img=cv2.bitwise_and(img,mask)\n",
    "    \n",
    "    bbox=cv2.boundingRect(points)\n",
    "    x,y,w,h=bbox\n",
    "    imgCrop=img[y:y+h,x:x+w]\n",
    "    imgCrop=cv2.resize(imgCrop,(0,0),None,5,5)\n",
    "    return mask\n",
    "# Taking an image as input\n",
    "img=cv2.imread('facefilter.jpg')\n",
    "# Resizing the image according to the requirement\n",
    "img=cv2.resize(img,(0,0),None,0.5,0.5)\n",
    "# Creating a copy of original image\n",
    "imgOriginal=img.copy()\n",
    "# Converting image to grayscale\n",
    "imgGray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "# detecting face using frontal face detector\n",
    "faces=detector(imgGray)\n",
    "# array to get landmarks points\n",
    "myPoints=[]\n",
    "# Iterating through faces in an image\n",
    "for face in faces:\n",
    "#     Getting top bottom right left axis of the face\n",
    "    x1,y1=face.left(),face.top()\n",
    "    x2,y2=face.right(),face.bottom()\n",
    "#     Drawing bounding box around the face\n",
    "    imgOriginal=cv2.rectangle(img,(x1,y1),(x2,y2),(0,255,0),2)\n",
    "#     Getting landmarks from face\n",
    "    landmarks=predictor(imgGray,face)\n",
    "    for n in range (68):\n",
    "#         Getting all landmarks and stroing it in array\n",
    "        x=landmarks.part(n).x\n",
    "        y=landmarks.part(n).y\n",
    "        myPoints.append([x,y])\n",
    "#         Displaying landmarks value on the face \n",
    "#         cv2.circle(imgOriginal,(x,y),5,(50,50,255),cv2.FILLED)\n",
    "#         cv2.putText(imgOriginal,str(n),(x,y-10),cv2.FONT_HERSHEY_COMPLEX_SMALL,0.8,(0,0,255),1)\n",
    "    \n",
    "    myPoints=np.array(myPoints)\n",
    "#         Creating box around lips\n",
    "    imgLips=createBox(img,myPoints[48:60])\n",
    "    cv2.imshow('Lips',imgLips)\n",
    "#     Coloring the lips\n",
    "    imgColorLips=np.zeros_like(imgLips)\n",
    "#     Lip color purpule\n",
    "    imgColorLips[:]=153,0,157\n",
    "    cv2.imshow('Colorlips',imgColorLips)\n",
    "    \n",
    "#     Taking and of color image with original image of lips\n",
    "    imgColorLips=cv2.bitwise_and(imgLips,imgColorLips)\n",
    "#     Taking Guassian blur to make it look more real\n",
    "    imgColorLips=cv2.GaussianBlur(imgColorLips,(7,7),10)\n",
    "#     Blending with original image so the lip color get changed on original image\n",
    "    imgColorLips=cv2.addWeighted(imgOriginal,1,imgColorLips,0.4,0)\n",
    "# Displaying colorLip image\n",
    "    cv2.imshow('ColorLips',imgColorLips)\n",
    "\n",
    "\n",
    "cv2.imshow('Original',imgOriginal)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e53c3e17",
   "metadata": {},
   "source": [
    "# Applying Cartoon Filter to the Face "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34c23098",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "\n",
    "# Load the image\n",
    "img = cv2.imread('facefilter.jpg')\n",
    "img=cv2.resize(img,(0,0),None,0.5,0.5)\n",
    "\n",
    "# Load the 68 landmark detector model\n",
    "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "# Convert to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Detect the landmarks in the face\n",
    "rects = detector(gray,1)\n",
    "for (i, rect) in enumerate(rects):\n",
    "    landmarks = predictor(gray, rect)\n",
    "    \n",
    "    # Extract the facial landmarks corresponding to the face region\n",
    "    x, y, w, h = landmarks.part(0).x, landmarks.part(17).y, landmarks.part(16).x - landmarks.part(0).x, landmarks.part(8).y - landmarks.part(27).y\n",
    "   \n",
    "    # Create a mask for the face region using the extracted facial landmarks\n",
    "    mask = np.zeros((img.shape[0], img.shape[1]), dtype=np.uint8)\n",
    "    cv2.rectangle(mask, (x, y), (x+w, y+h), (255, 255, 255), -1)\n",
    "    gray = cv2.cvtColor(img[y:y+h, x:x+w], cv2.COLOR_BGR2GRAY)\n",
    "    blurImage = cv2.medianBlur(img[y:y+h, x:x+w], 1)\n",
    "    edges = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 9, 9)\n",
    "    # Apply the cartoonify effect to the face region\n",
    "    cartoon = cv2.bilateralFilter(img[y:y+h, x:x+w], 9, 75, 75)\n",
    "    cartoon = cv2.bitwise_and(cartoon, cartoon, mask = edges)\n",
    "    # Create a new array with the same size as the input image and copy the cartoonified face region onto it\n",
    "    cartoon_full = np.zeros_like(img)\n",
    "    cartoon_full[y:y+h, x:x+w] = cartoon\n",
    "    \n",
    "    # Blend the cartoonified face region with the original image\n",
    "    result = cv2.addWeighted(img, 1, cartoon_full, 0.9, 0)\n",
    "    img = result\n",
    "    \n",
    "# Display the cartoonified image\n",
    "cv2.imshow('Cartoonified Image', cartoon)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb98cbb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
